**Обучающий (тренировочный) набор данных (обучающая выборка)** - набор данных, на котором будет обучаться алгоритм машинного обучения 
**Объекты** наблюдения - строки в наборе данных 
**Признаки** - переменные, столбцы в наборе данных 
**Целевой признак** -  признак, который нужно предсказать
**Обучение с учителем** - класс задач, в котором по обучающему набору данных (с известными значениями целевого показателя) нужно натренировать модель, предсказывающую для новых данных значения целевого признака 
**Классификация** - подзадача обучения с учителем, в которой целевой признак - категориальный 
**Бинарная классификация** - классификация, в котрой у целевого признака только две категории 
**Регрессия** - подзадача обучения с учителем, в которой целевой признак - количественный


## [Тема 03. Качество модели](https://practicum.yandex.ru/trainer/data-scientist/lesson/f5112556-e0ae-4eb2-9ae6-eec7e8f74e68/)
-   Узнаете, что такое тестовый набор данных.
-   Познакомитесь с переобучением.
-   Выясните, как измерять качество модели.

Продолжим разрабатывать алгоритм автоматического определения цены на квартиру.

### [Урок 2 Случайность в алгоритмах обучения](https://practicum.yandex.ru/trainer/data-scientist/lesson/73a274c7-a3c3-4f58-ace0-2b012967ccce/)
При обучении решающего дерева каждый раз получается новая модель. Как же проводить экзамен, если неизвестно, кто на него придёт?
Чтобы модели лучше замечали в данных зависимости, во многие алгоритмы машинного обучения добавляется случайность. Чтобы модели лучше замечали в данных зависимости, во многие алгоритмы машинного обучения добавляется случайность.

По-настоящему случайные числа компьютер не создаёт. Он подключает **генераторы псевдослучайных чисел**, которые производят последовательности, похожие на случайные. Например, по числу нельзя отгадать следующее. Со случайными числами не всё так просто: они непредсказуемы. Сегодня вы обучили искусственный интеллект, который завалит человечество спамом, а завтра он не может отличить кошку от собаки.
Зафиксировать псевдослучайность для алгоритма обучения очень просто: при его создании нужно указать параметр `random_state` (англ. «случайное состояние»).
Генераторы псевдослучайных чисел можно настроить так, чтобы результаты неизменно получались одинаковыми. Числа случайные, но при этом каждый раз одинаковые, как же так? На самом деле, они лишь выглядят случайными.
Карточки с переводом были настолько успешны, что вы решили обучать по ним других. Но прежде подготовили и записали разный порядок карточек на каждый день. В этих же последовательностях раскладываете их перед учениками. Так вы знаете, какая карточка будет восьмой по счёту, например, в пятницу. Образовательному процессу это не повредит: для ученика порядок будет выглядеть всё равно случайным.
Зафиксировать псевдослучайность для алгоритма обучения очень просто: при его создании нужно указать параметр `random_state` (англ. «случайное состояние»).

```python
# указываем случайное состояние (число)
model = DecisionTreeClassifier(random_state=12345)

# обучаем модель как раньше
model.fit(features, target)
```
В этой теме в `random_state` запишем `12345`. Вы можете задать любое значение (`54321` или `123`, или `0`) и даже строку. Главное — не менять его при каждом вызове. А если укажете `random_state=None`(по умолчанию), то псевдослучайность будет разной всегда.
**Зачем в алгоритмах указывают параметр `random_state`?**
А если укажете `random_state=None`(по умолчанию), то псевдослучайность будет разной всегда.
Параметр указывается, чтобы повторить удачный эксперимент.
Плачевно терять удачные результаты. То чувство, когда в начале нулевых играешь в приставку, проходишь уровень, над которым бился неделю. Но так сильно радуешься, что забываешь сохранить прогресс.

### [Урок 3  Тестовый набор данных](https://practicum.yandex.ru/trainer/data-scientist/lesson/2e591530-e30d-4713-9c59-9a45b0a6af4d/task/24898829-1ba8-492f-a70a-6625e4132a5d/)
Поймали модель и повели на экзамен. Но как проверить её знания? Нужен новый набор данных с известными ответами.
код обучения модели:
```python
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
df = pd.read_csv('train_data.csv')

df.loc[df['last_price'] > 5650000, 'price_class'] = 1
df.loc[df['last_price'] <= 5650000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier(random_state=12345)
model.fit(features, target)
```
Чтобы знать точно, что модель не вызубрила ответы, возьмём новый датасет — **тестовый набор данных**, или **тестовую выборку**. Файл с данными назовём `test_data.csv` (англ. «тестовые данные»). Проверим, как модель с ними справится.

#### Урок 3. Задача 1
Загрузите в переменную `test_df` три первых объекта из тестовой выборки. Подготовьте их к классификации: сохраните признаки в переменной `test_features` (англ. «признаки для теста»), а целевой признак — в `test_target` (англ. «цель теста»). Предскажите ответы.
Предсказания сохраните в переменной `test_predictions`.
Переводить переменные из _np.array_ в _list_ не нужно. Выясните, много ли ошибок допустила модель?
Всё как в работе с обучающей выборкой. Загрузите данные, преобразуйте исходную задачу регрессии в задачу классификации. Сохраните признаки в переменной _test_features_ (англ. «признаки для теста») и целевой признак — в _test_target_ (англ. «цель теста»).
```python
import pandas as pd
from sklearn.tree import DecisionTreeClassifier

# обучающая выборка находится в файле train_data.csv
df = pd.read_csv('/datasets/train_data.csv')

df.loc[df['last_price'] > 5650000, 'price_class'] = 1
df.loc[df['last_price'] <= 5650000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier(random_state=12345)

# обучите модель вызовом метода fit()
model.fit(features, target)

test_df = pd.read_csv('/datasets/test_data.csv')[0:3]
test_df['price_class'] = test_df['last_price'].apply(lambda x: 1. if x > 5650000 else 0)

test_features = test_df.drop(['last_price','price_class'], axis=1)
test_target = test_df['price_class']

test_predictions = model.predict(test_features)
print('Предсказания:',test_predictions)
print('Правильные ответы:',test_target.values)
# < напишите код здесь >

```

#### Урок 3. Задача 2
Трёх примеров недостаточно, чтобы понять, хорошо или плохо работает модель. Посчитайте количество ошибок модели на всей тестовой выборке.

Напишите функцию `error_count()`(англ. «подсчёт ошибок»), которая:
1.  Принимает на вход правильные ответы и предсказания модели.
2.  Сравнивает их в цикле `for`.
3.  Возвращает количество расхождений между ними.   
Выведите результат работы `error_count()` с тестовым набором в указанном формате:
Алгоритм работы функции `error_count()`:
— Создать переменную-счётчик и присвоить ей значение `0`;
— Сделать цикл по длине ответов и предсказаний:
-   Проверить, совпадает ли очередной ответ с новым предсказанием;
-   Если не совпадает, прибавить `1` к счётчику.
``` python
import pandas as pd
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv('/datasets/train_data.csv')

df.loc[df['last_price'] > 5650000, 'price_class'] = 1
df.loc[df['last_price'] <= 5650000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier(random_state=12345)

model.fit(features, target)

test_df = pd.read_csv('/datasets/test_data.csv')

test_df.loc[test_df['last_price'] > 5650000, 'price_class'] = 1
test_df.loc[test_df['last_price'] <= 5650000, 'price_class'] = 0

test_features = test_df.drop(['last_price', 'price_class'], axis=1)
test_target = test_df['price_class']
test_predictions = model.predict(test_features)

def error_count(answers, predictions):
    error_count=0
    for i in range(len(predictions)):
        if answers[i] != predictions[i]:
            error_count+=1
    return error_count
print("Ошибок:", error_count(test_target, test_predictions))
```

### [Урок 4 Доля правильных ответов](https://practicum.yandex.ru/trainer/data-scientist/lesson/d3ae3ebb-bedd-4eaf-8989-0de39bc19e3e/task/27beb0b8-c907-4006-8894-c6cd5643db3e/)
Если на экзамене задавать много вопросов, можно завалить даже идеально обученную модель. Сопоставим количество ошибок с размером тестовой выборки, чтобы понять, сильно ли наша модель промахнулась.
Отношение числа правильных ответов к размеру тестовой выборки называется `accuracy` (англ. «правильность»), в некоторых переводах — «доля правильных ответов». Формула выглядит так:
![image|320](https://pictures.s3.yandex.net/resources/accuracy_1573566344.jpg)

#### Урок 4. Задача 1

Напишите функцию `accuracy()`, которая:
1.  Принимает на вход правильные ответы и предсказания,
2.  Сравнивает их в цикле `for`.
3.  Возвращает долю правильных ответов.
Получится функция, похожая на `error_count()`.
Выведите на экран `accuracy` модели в указанном формате:
``` python
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
df = pd.read_csv('/datasets/train_data.csv')

df.loc[df['last_price'] > 5650000, 'price_class'] = 1
df.loc[df['last_price'] <= 5650000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier(random_state=12345)
model.fit(features, target)

test_df = pd.read_csv('/datasets/test_data.csv')
test_df.loc[test_df['last_price'] > 5650000, 'price_class'] = 1
test_df.loc[test_df['last_price'] <= 5650000, 'price_class'] = 0

test_features = test_df.drop(['last_price', 'price_class'], axis=1)
test_target = test_df['price_class']
test_predictions = model.predict(test_features)

def error_count(answers, predictions):
    count = 0
    for i in range(len(answers)):
        if answers[i] != predictions[i]:
            count += 1
    return count

def accuracy (answers, predictions):
    count_accuracy =0
    for i in range(len(predictions)):
        if answers[i] == predictions[i]:
            count_accuracy += 1
    accuracy = count_accuracy/len(predictions)
    return accuracy
print("Accuracy:", accuracy(test_target, test_predictions))
```

### [Урок 5 Метрики качества](https://practicum.yandex.ru/trainer/data-scientist/lesson/3587ffcc-e366-4480-ba00-0e2aee4449dc/)

Можно ли отличить хорошую модель от плохой? Как оценить качество модели? Какую метрику выбрать?
Метрики качества оценивают качество работы и выражаются в числовой форме.
-   Правильность (англ. `accuracy`) отношение числа правильных ответов к размеру тестовой выборки 
-   Точность (англ. `precision`) показывает, какая доля объектов, отмеченных моделью как дорогие, действительно стоят дорого (ответ `1`).
-   Полнота (англ. `recall`) выявляет, какую часть дорогих объектов выделила модель.
Метрики качества тесно связаны с исходной задачей классификации. Почему, определяя цены на квартиры, мы выбрали `accuracy`? Каждое неправильное предсказание — это неверная подсказка и потенциальная упущенная выгода для продавца. И наоборот: чем выше точность классификации, тем больше прибыли принесёт продукт.
Да, чем выше качество модели, тем лучше. Но её внедрение должно быть оправданно. Очевидные границы: `accuracy` не может быть меньше нуля (все ответы неправильные) и больше единицы (все ответы правильные). 
Допустим, перед вами модель, которая предсказывает все объекты случайным образом. С вероятностью 50/50 ответ будет `0` или `1`. Чему равна `accuracy` такой модели? Напомним: классы в задаче про квартиры распределены поровну. **Ответ: 0.5.** 0 из 4 правильно и 1 неправильно
Рассмотрим отдельно ответы `1` (дорогие квартиры) и `0` (дешёвые квартиры):
`accuracy` = 0.5 * (доля угаданных 1) + 0.5 * (доля угаданных 0)
Ответы модели не связаны с правильными ответами, поэтому вероятность угадать `1` равна 50 % — так же и для `0`. `Accuracy` будет равна 0.5.
`accuracy` = 0.5 * 0.5 + 0.5 * 0.5 = 0.5
Если `accuracy == 0.4`, какое качество модели? Низкое! Даже случайные ответы дают результат лучше.
Всегда сравнивайте модель со случайной, так вы сможете оценить её адекватность, или проверить на вменяемость (англ. _sanity check_).

