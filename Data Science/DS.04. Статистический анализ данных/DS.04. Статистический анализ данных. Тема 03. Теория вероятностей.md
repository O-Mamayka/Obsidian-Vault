## [DS.04. Статистический анализ данных. Тема 03. Теория вероятностей](https://practicum.yandex.ru/trainer/data-scientist/lesson/ebe1ad5b-998e-4cff-910d-225a8f2952c1/task/03ff3dd3-bc30-438d-b12f-6aa34d9f91de/)

Вы изучите основы аксиоматики Колмогорова: узнаете, чем событие отличается от случайной величины и как устроены некоторые важные — часто наблюдаемые в реальном мире — распределения вероятностей.

-   понимать закон больших чисел и центральную предельную теорему (в одной из формулировок);
-   моделировать биномиальное распределение на Python, аппроксимировать его нормальным распределением в тех случаях, когда это возможно;
-   работать с нормальным распределением на Python: искать значения по вероятностям и наоборот.


### [Урок 2. Эксперименты, элементарные исходы, события](https://practicum.yandex.ru/trainer/data-scientist/lesson/33a9da3e-6ac1-4573-8e3a-cd7f536a181a/)

**Эксперимент** — это повторяемый опыт, который может окончиться **элементарными исходами**. Они так названы из-за своего простого устройства: исход либо случился, либо нет.
В простейшем случае исходы не отличаются: вероятность каждого из них одинакова. Такие исходы называются **равновероятные**.
-   Пустое множество. Оно не содержит ничего: с точки зрения математики, это законно. Вы уже знаете, что если эксперимент проведён, какой-то элементарный исход должен стать его результатом. Вероятность пустого подмножества при этом равна нулю — поэтому событие, состоящее из пустого подмножества вероятностного пространства, называется **невозможным;**
-   Множество, содержащее в себе все возможные исходы — подмножество вероятностного пространства, равное ему самому. Такое событие точно, с вероятностью 1, произойдет при проведении эксперимента, поэтому оно называется **достоверным**.
Остальные события расположены между этими крайностями, и их вероятность лежит в промежутке от 0 до 1.
При сохранении условия равновероятности всех элементарных исходов **вероятность события** — количество исходов, входящих в это событие, делённое на общее количество исходов, то есть на размер вероятностного пространства.
Исходы — это песни, которые могут быть проигранными первыми, а событие — то, что первая включённая песня принадлежит группе _Queen_. Так, событие состоит из нескольких исходов.
Не дайте себя обмануть! Выражение «исход события» не имеет смысла. Исходы бывают только у эксперимента, и могут попасть в подмножество, названное событием, или не попасть.

### [Урок 3. Закон больших чисел](https://practicum.yandex.ru/trainer/data-scientist/lesson/7017a06d-bce6-4a2b-b5e8-712d37632d0d/task/3a588b32-fcc9-4bb9-816c-8fc271c833bc/)
Вероятность события тесно связана с его частотой при многократном повторении эксперимента.

**Закон больших чисел** — известная закономерность: чем больше раз повторяется эксперимент, тем ближе частота заданного на этом эксперименте события будет к его вероятности. Если многопятновый питон — обладатель 7 или 8 пятен, а всего пятен может быть от 3 до 8, то чем больше питонов вырастет в питоноинкубаторе, тем ближе к 1/3 будет доля многопятновых среди них.
Это правило работает и в обратную сторону. Если мы не знаем вероятность какого-нибудь события, но можем много раз повторить эксперимент, то о ней можно судить по частоте входящих в него исходов.

#### Урок 3. Задача
Яндекс отслеживает количество удачных постов определённого блога для Дзена. Абсолютно удачным постом считается такой, у которого число репостов сравнимо с числом лайков. Этот успех считаем за 100%.
Сгенерируйте 20, 400, 10000 случайных целых чисел из отрезка [1, 100]. Это соотношение репостов к лайкам в популяции блогеров в целом. Если для избранного блогера соотношение всегда выше, он причисляется к хорошим.
Для каждого набора чисел вычислите вероятность события «Сгенерированное число лежит в отрезке [21, 40]» (самая типичная доля репостов). Сохраните её в переменных `p_20`, `p_400` и `p_10000` соответственно.
```python
import random
random.seed(1111)  # метод seed() задаёт степень случайности, не меняйте её
def calculate_p(N):
    cnt_21_40 = 0
    for i in range(N):
        random_integer = random.randint(1,100) # ваш код здесь
        if (random_integer >=21) and (random_integer<=40):
            cnt_21_40 +=1
    return cnt_21_40/N

p_20 = calculate_p(20)
p_400 = calculate_p(400)
p_10000 = calculate_p(10000)
print(p_20, p_400, p_10000)
out: 0.15 0.255 0.2003
```
По закону больших чисел: чем больше раз повторяется эксперимент, тем ближе частота события к его вероятности. В этой задаче — к 20%. Если у вас при увеличении числа экспериментов вероятность события становится дальше от 20%, не пугайтесь. Вероятность этого очень мала, но не нулевая.

### Урок 4. Взаимоисключающие и независимые события, умножение вероятностей
Для каждого из шести исходов взросления первого питона может выпасть шесть исходов взросления второго — всего 36. Их можно обозначить так:

![image|320x240](https://pictures.s3.yandex.net/resources/5-3-3-1_1565075900.jpg)
Разными цветами обозначены события «суммарно на двух питонах появилось _k_ пятен» (_k_ может быть от 2 до 12). Вероятности этих событий не равны: в них входит разное количество элементарных исходов.
Некоторые события могут иметь общие исходы — на диаграмме, отображающей все элементарные исходы, они пересекутся.
Например, будут иметь общие исходы событие А — на питонах в сумме появилось больше восьми пятен — и событие Б — на питонах появилось одинаковое количество пятен:
![image|320x240](https://pictures.s3.yandex.net/resources/____4_1564228721.jpg)
Элементарные исходы «на обоих питонах появилось по пять пятен» (в сумме десять) и «на обоих питонах появилось по шесть пятен» (в сумме двенадцать) входят в оба события.
Схематично такой случай можно отобразить на **диаграмме Эйлера-Венна**. На ней не указывают элементарные исходы, а лишь отношения пересечения между событиями:

![image|200x120](https://pictures.s3.yandex.net/resources/jpg_1_1564227904)
События А и Б пересекаются, значит существуют элементарные исходы, входящие и в А, и в Б.
**Взаимоисключающими** называют события, которые не могут произойти одновременно при проведении эксперимента — на диаграмме Эйлера-Венна они не пересекаются. Вероятность пересечения взаимоисключающих событий равна нулю.
События называют **независимыми**, если наступление одного из них не влияет на вероятность другого.
**Когда события независимы, то вероятность их пересечения равна произведению их вероятностей.** Это правило работает и в обратную сторону.
На том же вероятностном пространстве события «у одного из питонов ровно два пятна» и «у питонов в сумме 7 пятен», **Зависимы**. Вероятность семи пятен в сумме равна 6/36 или 1/6; вероятность ровно двух пятен у одного из них — 11/36; вероятность пересечения — 2/36. 1/6 * 11/36 ≠ 2/36: события зависимы. Наступление одного из них меняет вероятность наступления другого.

![image|240](https://pictures.s3.yandex.net/resources/pitony2_1656501621.jpg)
Взаимоисключающие события **не** могут быть независимыми, вероятность каждого из которых больше нуля! Чтобы события были независимыми, вероятность их пересечения должна быть равна произведению их вероятностей. Произведение их вероятностей будет точно больше нуля, ведь по условию задачи у каждого из них ненулевая вероятность. А вероятность пересечения взаимоисключающих событий равна нулю. Условие независимости не может быть выполнено. Это логично: наступление одного из этих событий исключает наступление другого, то есть влияет на вероятность, что оно произойдет. А значит, взаимоисключающие события не независимы.
Если взаимоисключающие события охватывают всё вероятностное пространство, сумма их вероятностей равна единице.
Взаимоисключаемость событий видна на диаграмме **Эйлера-Венна**. А вот независимость так просто не обнаружишь, нужно проверять условие равенства произведения вероятностей событий вероятности их пересечения. Для нахождения вероятности пересечения независимых событий (произойдёт и то, и другое) нужно найти произведение их вероятностей.
Пускай питон ползёт по лабиринту в попытках найти выход. На каждом разветвлении он с равной вероятностью выбирает один из доступных ему путей.
![image|320](https://pictures.s3.yandex.net/resources/Labirint_1589282118.png)
На первой развилке у него два варианта продолжения пути; на второй — три; на третьей — пять. Только на одном из тридцати возможных путей питон достигнет свободы. Вероятности можно перемножать, так как выбор происходит независимо от предыдущих.
_Вероятность того, что случайный пользователь указал мужской пол, равна 0,29. Вероятность, что случайный пользователь не указал свой пол, равна (1 - 0,29 - 0,25) = 0,46. События независимы. Значит, вероятность того, что они произойдут именно в таком порядке, равна 0,46 * 0,29 = 0,1334 или 13,34 %._

### Урок 5. Случайные величины, распределение вероятностей и интервалы значений
эксперимент, элементарные исходы, события и вероятность - это набор поможет понять смысл **случайной величины**.
Случайная величина — это переменная, которая принимает случайные значения. «Случайные» — значит нельзя предсказать, какое именно значение примет величина. У эксперимента есть исходы, которые могут описываться как количественно, так и качественно.
Случайная же величина определяется на этих исходах _численно_. Это способ спроецировать исходы эксперимента, как бы они ни определялись, на числовую ось.

Для одного и того же эксперимента это делают по-разному. Например, исход эксперимента, когда питон выбирается из лабиринта, можно обозначить нулём. А когда не выбрался — единицей. Или наоборот. Или же сотней, если выбрался, и тысячей — если нет. После такого определения можно работать с числами, обычно это удобнее.
Как и все количественные переменные, случайная величина может быть дискретной или непрерывной. Например, масса питонов — непрерывная величина, а количество питонов, достигших возраста покрывания пятнами — дискретная.
Соберём все возможные значения сумм и укажем соответствующие им вероятности в таблице:

Случайная величина «Сумма пятен на двух питонах»

Вероятность этого значения

Случайная величина «Сумма пятен на двух питонах»|Вероятность этого значения 
 -|-
 2|1/36
 3|2/36
 4|3/36
 5|4/36
 6|5/36
 7|6/36
 8|5/36
 9|4/36
 10|3/36
 11|2/26
12|1/36|
Такая таблица называется **распределением вероятностей** случайной величины.
Построим такую таблицу в Python. Поместим данные о пятнах питона в массив _numpy array_:
```python
spots = np.array([[2,3,4,5,6,7], # имя переменной spots по-английски значит «пятна»
    [3,4,5,6,7,8], 
    [4,5,6,7,8,9], 
    [5,6,7,8,9,10], 
    [6,7,8,9,10,11],
    [7,8,9,10,11,12]])
```

```
spot_probs={k:spot_counts[k]/36 for k in spot_counts}
print(spot_probs)
```
Выражение, которое мы применили — генератор данных для словаря. В документации или англоязычной литературе вы можете встретить его другое название: _dictionary comprehension_ (англ. «описание словаря»).
Если мы возьмём не сумму, а произведение количества пятен, это будет другая случайная величина. Вероятностное пространство будет выглядеть так:
![image|220](https://pictures.s3.yandex.net/resources/____1.1_1564231614.jpg)
Найдем распределение вероятностей для этого вероятностного пространства и построим гистограмму:
```python
import pandas as pd
x = pd.Series([1, 2, 3, 4, 5, 6, 2, 4, 6, 8, 10, 12, 3, 6, 9, 12, 15, 18, 4, 8, 12, 16, 20, 24, 5, 10, 15, 20, 25, 30, 6, 12, 18, 24, 30, 36])
x.hist(density=True, bins=36)
```
Аргумент _density_ со значением _True_ нужен для построения гистограммы плотности вероятностей. Количество корзин равно количеству значений — это значит, что по вертикальной оси будут вероятности для каждого значения.
Получим гистограмму:
![image|240](https://pictures.s3.yandex.net/resources/Untitled_1564231681.png)
Наиболее вероятные значения: 6 и 12. Они встречаются в вероятностном пространстве по 4 раза, то есть вероятность каждого из них — 4/36 или 1/9.
Заметим, что для любой случайной величины выполняется известное вам правило: сумма вероятностей всех возможных исходов равна единице.


#### Урок 5. Задача 1
`spot_matrix` - «сумма количества пятен двух питонов, у которых с равной вероятностью могут появиться от 5 до 10 пятен».
Составьте словарь `spot_probs` с распределением вероятностей для этой случайной величины. Ключами в словаре должны быть целые числа — возможные исходы эксперимента (тип `int`), значениями — вероятности исходов типа `float`. Выведите значение переменной `spot_probs` на экран.
Попробуйте проитерироваться по возможным значениям количества пятен для первого питона, и для каждого из них проитерироваться по количеству пятен для второго питона. Сумма, полученная на каждой итерации — это исход эксперимента.
```python
import numpy as np
spot_matrix = np.array(
    [
        [10, 11, 12, 13, 14, 15],
        [11, 12, 13, 14, 15, 16],
        [12, 13, 14, 15, 16, 17],
        [13, 14, 15, 16, 17, 18],
        [14, 15, 16, 17, 18, 19],
        [15, 16, 17, 18, 19, 20],
    ]
)
spot_counts = {}
for i in range (0,6):
    for j in range (0,6):
        if spot_matrix[i][j] not in spot_counts.keys():
            spot_counts[spot_matrix[i][j]] = 1
        else:
            spot_counts[spot_matrix[i][j]] += 1

spot_probs = {k:spot_counts[k]/36 for k in spot_counts } # код словаря
print(spot_probs)
```

#### Урок 5. Задача 2
Проверьте, что сумма вероятностей всех возможных исходов равна единице. Округлите результат и запишите в переменную `sum_probs_one`. Выведите её на экран. Не удаляйте вывод `spot_probs` из предыдущего задания.
Значения словаря получают вызовом метода `values()`, а их сумму — передавая значения как аргумент методу `sum()`. Чтобы обойтись без квадриллионных долей, округлите результат.
```python
sum_probs_one = int(sum(spot_probs.values()))
```

### Урок 6. Математическое ожидание и дисперсия
чем больше раз повторяется эксперимент, тем ближе частота заданного на эксперименте события будет к его вероятности.
Если событие — подмножество вероятностного пространства, значит, можно взять все возможные исходы и объявить их событием. Применим закон больших чисел: к чему будут стремиться результаты эксперимента, если повторять его много раз? Для эксперимента можно задать случайную величину и найти численное значение, к которому она будет в среднем стремиться при многократном повторе эксперимента. Это значение называется математическим ожиданием случайной величины.
Если эксперимент состоит из равновероятных элементарных исходов, заданных численно, математическое ожидание будет равно среднему возможных значений.
Если выращивать сотни питонов вида от-одного-до-шести-пятновые, то даже если у первых нескольких питонов будет очень мало или очень много пятен, с ростом количества наблюдений среднее количество пятен будет стремиться к `(1+2+3+4+5+6)/6 = 3,5`.
Стремление значений к математическому ожиданию иллюстрирует график:
![image|320](https://pictures.s3.yandex.net/resources/jpg_1564562604)
Математическое ожидание равно среднему, если исходы равновероятны. Но что если вероятности разных значений случайной величины отличаются? К чему тогда будет стремиться среднее при повторении экспериментов?
**Математическое ожидание случайной величины** — сумма всех значений случайной величины, помноженных на их вероятности:
![image|340](https://pictures.s3.yandex.net/resources/Screenshot_1564261717.png)
Математическое ожидание случайной величины _X_ обозначается буквой _E_ (от англ. _expected value,_ «ожидаемое значение»); вероятность значения _x_ — буквой _p_ (от лат. _probabilitas_, «вероятность»).
К примеру, пусть распределение вероятностей случайной величины задано таблицей:
![image](https://pictures.s3.yandex.net/resources/jpg_1_1564261766)
Преобразуем таблицу в словарь и найдём математическое ожидание по формуле:
```python
x_probs = {
        '3': 0.1,
        '4': 0.2,
        '5' : 0.2,
        '7' : 0.3,
        '11' : 0.1,
        '16' : 0.05,
        '18': 0.05    
}
# E(X): для каждого элемента словаря вычисляем произведение вероятности и значения 
# случайной величины (целочисленное представление ключа словаря):
expectation = sum([int(x_i)*x_probs[x_i] for x_i in x_probs]) 
print(expectation)
```




Математическое ожидание — аналог характеристики положения, только не для датасета, а для случайной величины. Оно показывает, вокруг какого значения распределена случайная величина, и — по закону больших чисел — к какому значению она будет в среднем стремиться при повторениях эксперимента.
Поскольку случайная величина распределена вокруг этой «характеристики положения», можно найти и меру её разброса.
Для этого нужно найти математическое ожидание квадрата случайной величины. Это несложно, ведь значения меняются, а их вероятности — нет.
Зная математическое ожидание самой случайной величины и её квадрата, дисперсию находят по формуле:
![image|480](https://pictures.s3.yandex.net/resources/Screenshot_1_1564261849.png)
Распределение вероятностей случайной величины задано таблицей:
![image|480](https://pictures.s3.yandex.net/resources/jpg_1564261922)

```python
x_probs = {
    '3': 0.1,
    '4': 0.2,
    '5': 0.2,
    '7': 0.3,
    '11': 0.1,
    '16': 0.05,
    '18': 0.05
}
# E(X): для каждого элемента словаря вычисляем произведение вероятности и значения
# случайной величины (целочисленное представление ключа словаря):
expectation = sum([int(x_i) * x_probs[x_i] for x_i in x_probs])
# (E(X))^2
square_of_expectation = expectation ** 2
# E(X^2)
expectation_of_squares = sum(
    [int(x_i) * int(x_i) * x_probs[x_i] for x_i in x_probs]
)
variance = expectation_of_squares - square_of_expectation
print(variance) 
```

```
Out: 15.899999999999991 
```

Корень из дисперсии примерно равен четырём — это стандартное отклонение. Математическое ожидание равно семи.
Правило трёх сигм работает: в промежутке 7 ± (4 * 2) расположены все значения, кроме 16 и 18, а в промежутке 7 ± (4 * 3) лежат все значения случайной величины.

#### Урок 6. Задача 1
В переменной `x_probs` в виде словаря задано распределение вероятностей случайной величины _X —_ апрельской температуры в городе _N_. Найдите её математическое ожидание и дисперсию. Сохраните результаты в переменных `expectation`(англ. «ожидание») и `variance` (англ. «разброс»). Выведите их на экран.
Найдите математическое ожидание и дисперсию по формулам из урока.
Найти математическое ожидание можно так:
```python
expectation = sum([int(x_i)*x_probs[x_i] for x_i in x_probs]) 
```
Для нахождения дисперсии посчитайте квадрат математического ожидания и математическое ожидание квадратов:
```python
square_of_expectation = expectation ** 2
expectation_of_squares = sum([int(x_i)*int(x_i)*x_probs[x_i] for x_i in x_probs]) 
```
Для нахождения дисперсии найдите разность между математическим ожиданием квадратов и квадратом математического ожидания.
```python
import numpy as np
x_probs = {
    '-4': 0.05,
    '-2': 0.25,
    '0': 0.1,
    '1': 0.1,
    '5': 0.1,
    '7': 0.05,
    '15': 0.35,
}

# здесь код ваших вычислений
expectation=sum(int(key)*x_probs[key] for key in x_probs)
expectation_x2=sum(int(key)**2*x_probs[key] for key in x_probs)
variance=expectation_x2-expectation**2
print('Математическое ожидание равно', expectation)
print('Дисперсия равна', variance)
```

```
Математическое ожидание равно 5.5
Дисперсия равна 55.349999999999994
```

#### Урок 6. Задача 2
Известно, что питоны разных знаков Зодиака дорастают до различного взрослого веса. Водные знаки весят 2 кг, Огненные и Земляные — 3 кг, Воздушные — 5 кг. Питоны рождаются с одинаковой частотой на протяжении всего года.
Запишите в словарь `weight_probs` распределение вероятностей для случайной величины «Вес питона». В качестве ключей словаря используйте строковые значения, а не числовые. Найдите математическое ожидание и дисперсию случайной величины, запишите их в переменные `expectation` и `variance`. Результат выведите на экран.
```python
import numpy as np

# Вероятность того, что отдельно взятый питон окажется одним из 12 знаков Зодиака, равна 1/12.
# Вероятность того, что он принадлежит к одной из 4 стихий, равна 1/4.
# Вероятности для двух стихий - Огня и Земли - нужно сложить, чтобы получить вероятность
# того, что питон весит 3 кг, для остальных просто остается 1/4.
weight_probs = {'2':0.25,'3':0.5,'5':0.25}
# здесь код создания словаря и расчётов
expectation=sum([int(k)*weight_probs[k] for k in weight_probs])
expectation_x2=sum([int(k)**2*weight_probs[k] for k in weight_probs])
variance=expectation_x2-(expectation)**2
print('Математическое ожидание равно', expectation)
print('Дисперсия равна', variance)
```

```
Математическое ожидание равно 3.25
Дисперсия равна 1.1875
```

### [Урок 7. Вероятность успеха в биномиальном эксперименте](https://practicum.yandex.ru/trainer/data-scientist/lesson/acf6c9b2-2a91-4b7f-bb57-a3d483d7ad9c/)
Часто встречаются эксперименты всего с двумя исходами. Такие эксперименты называются **биномиальными** (от лат. _bis_ — «два», _nomen_ — «имя»).
Обычно один из результатов называют успехом, а второй, соответственно, неудачей. Если вероятность успеха равна `p`, то вероятность неудачи `(1 - p)`, ведь сумма вероятностей всех исходов эксперимента должна быть равна единице.
Например, если нас интересует комбинация из четырёх подряд экспериментов: Успех-Успех-Неудача-Успех, то её вероятность можно найти по формуле `p⋅p⋅(1-p)⋅p`, если обозначить вероятность успеха за _p_.
Пользователь попадает в рекламный баннер с первого клика в 88% случаев. В 12% случаев промахивается: попадает на страницу рядом с баннером.
Какова вероятность, что из 5 независимо кликающих по баннеру пользователей первые три попадут по баннеру, а следующие двое промажут?
```PYTHON
a = 0.88 # вероятность, что пользователь попадёт по баннеру
b = 0.12 # вероятность, что пользователь промажет
prob = a * a * a * b * b
out: 0.0098131968 
```
Вероятность того, что в пятёрке независимо кликающих на баннеры пользователей случится именно такой порядок: три клика, а затем два непопадания, чуть меньше 1%.
Задача усложнится, если мы не будем знать, какой именно порядок успехов и неудач нам интересен.
Возьмем двух случайных питонов (их доброта и злость не зависят друг от друга). Какова вероятность, что один из них будет добрым, а другой — злым?
Первый злой, а второй добрый; и первый добрый, а второй злой — это разные исходы. Потому умножаем вероятности на 2. (= 18%).
Проверим результат задачи из теста, рассмотрев другие исходы. Оба добрые (вероятность 0.9 в квадрате, т. е. 0.81) плюс оба злые (вероятность 0.1 в квадрате, т. е. 0.01) покрывают 81% + 1% = 82% всех случаев. Остаются 18% на комбинацию доброго и злого.
В прикладных задачах чаще всего конкретный порядок неважен. Полезно найти вероятность того, что случится какое-то количество «успехов» из некоторого числа экспериментов. То есть на подобных вероятностных пространствах определяют случайную величину «количество успехов» (или неудач) и строят для неё распределение вероятностей. При этом порядок успехов и неудач не имеет значения, важно только сколько их будет — а значит, нужно домножать на число возможных комбинаций успехов и неудач.


### [Урок 8. Биномиальное распределение](https://practicum.yandex.ru/trainer/data-scientist/lesson/9e50c85b-6acf-4d98-b151-a7ec6a0d5dd1/task/dc7d59fc-ab51-4133-a4ab-517f23fbda86/)
![image|480](https://pictures.s3.yandex.net/resources/angry_python_2_1564263551.jpg)
Количество способов выбрать k успехов из n повторений эксперимента находят по формуле:
![image|320](https://pictures.s3.yandex.net/resources/Screenshot_1564263604.png)
где <число>! (читается как <число> факториал) равно произведению всех натуральных чисел от 1 до этого числа: n! = 1 ⋅ 2 ⋅ 3 ⋅ 4 ⋅ ... ⋅ (n-1) ⋅ n.

Изучим работу формулы на примере. По результатам розыгрыша в группе вашего проекта в социальной сети победитель выиграл билеты на три сеанса в кинотеатре.
По правилам конкурса победитель должен выбрать даты посещения кино в течение двух недель после розыгрыша, не более одного сеанса в день. Сколько вариантов выбора трёх из предстоящих четырнадцати дней есть у пользователя?
![image|480](https://pictures.s3.yandex.net/resources/123_1564263684.png)
У пользователя целых 364 варианта выбрать 3 дня из 14, чтобы пойти в кино. Или 364 варианта выбрать 11 дней из 14, чтобы не пойти в кино — результат будет тем же.
Тут поможет библиотека _math_ и её метод _factorial_:
```python
from math import factorial
c = factorial(14) / (factorial(3) * factorial(11))
print(c)
```
Вернёмся к задаче о биномиальном эксперименте (повторении эксперимента с двумя исходами n раз) в общем виде. Если вероятность успеха `p` и неуспеха `1 - p`, а эксперимент был повторён _n_ раз, то вероятность любого количества успехов _k_ из этих _n_ экспериментов:

![image](https://pictures.s3.yandex.net/resources/Screenshot_1564263782.png)

Успех произошёл _k_ раз, значит, мы перемножаем его вероятность _k_ раз, то есть возводим `p` в степень _k_. Если успех произошёл _k_ раз, то неудача произошла _n - k_ раз, и её вероятность `1-p` возводят в степень _n-k_. Чтобы учесть все возможные комбинации такого количества успехов и неудач, домножим результат на соответствующее число сочетаний.
Теперь вы легко сможете как посчитать вероятность конкретного количества успехов при известном числе попыток и вероятности успеха, так и построить для этих двух параметров полное распределение вероятности всех возможных вариантов числа успехов: от нуля (случилось _n_ неудач) до _n_ (случилось _n_ успехов).
Зафиксируем условия, при которых можно утверждать, что случайная величина распределена биномиально:
-   проводится конечное фиксированное число попыток _n_;
-   каждая попытка — простой биномиальный эксперимент ровно с двумя исходами;
-   попытки независимы между собой;
-   вероятность успеха _p_ одинаковая для всех _n_ попыток.

Приведём несколько примеров для разных _n_ и _p_: числа повторений изначального эксперимента и вероятности успеха в нём. По вертикальной оси отложим вероятность того или иного исхода, а по горизонтальной — возможное число успехов. Мы уже отмечали, что оно может варьироваться от нуля до _n_, т. е. всего возможен _n+1_ вариант.
При вероятности успеха, равной вероятности неудачи (то есть обе равны 50%), распределение будет симметричным.
Для n=5 и p=0.5:
```python
from matplotlib import pyplot as plt
from math import factorial
n = 5
p = 0.5
distr = []
for k in range(0, n + 1):
    choose = factorial(n) / (factorial(k) * factorial(n - k))
    prob = choose * p ** k * (1 - p) ** (n - k)
    distr.append(prob)
plt.bar(range(0, n + 1), distr)
```
![image|320](https://pictures.s3.yandex.net/resources/Untitled_1564263884.png)
А вот если вероятность успеха отличается от половины, а n при этом не слишком велико, распределение получается скошенным: вправо, если вероятность успеха маленькая; влево — если большая.
А при вероятности успеха в 90% очень маловероятно получить немного успехов. Например, при 26 повторениях практически всегда количество успехов будет больше 18.

#### Урок 8. Задача 1
В некоторые дни питонов в питонопитомнике кормят грушами, а в некоторые — яблоками.
На ближайшую неделю (7 дней) есть запас на 3 дня кормления грушами и на 4 дня кормления яблоками. День может быть только грушевым или только яблочным, смешивание фруктов не разрешается.
Вариант диеты — это, например, (груши, яблоки, груши, груши, яблоки, яблоки, яблоки).
Сколько разных вариантов грушево-яблочной диеты можно составить для питонов на ближайшую неделю? Запишите результат в переменную `n_diets` и выведите на экран.
Из семи дней нужно выбрать три дня для груш, т. е. выбрать три из семи возможных дней. Аналогичный результат получится, если выбрать четыре дня для яблок (оставшиеся автоматически станут грушевыми).
```python
from math import factorial
# Число способов выбрать k дней из n дней:
# C(n, k) =  n! / ( k! * (n-k)! )
n_diets=factorial(7)/(factorial(3)*factorial(7-3))
print(n_diets)
```

#### Урок 8. Задача 2
Питон Петя решил после питонопитомника поступить в питоноакадемию. Для этого ему надо сдать шесть разных (не зависящих друг от друга) экзаменов. Петя думает, что он отлично подготовился: вероятность завалить каждый из этих экзаменов, судя по пробным вариантам, для него равна 15%.
Постройте распределение вероятностей для случайной величины «количество заваленных Петей экзаменов» и гистограмму для нее.
```python
from matplotlib import pyplot as plt
from math import factorial
n_exams = 6 # количество экзаменов?
failure_rate = 0.15 #вероятность завалить один экзамен?
distr = [] #переменная, в которой хранится значения распределения
for k in range(0, n_exams + 1):    #  вероятность завалить 0 экзаменов, 1 экзамен и так далее до 6
    c = factorial(n_exams)/(factorial(k)*factorial(n_exams-k))
    P = c * failure_rate**k * (1-failure_rate)**(n_exams-k)
    distr.append(P)
# построение гистограммы распределения вероятностей
plt.bar(range(0,n_exams+1), distr)
```

#### Урок 8. Задача 3
Ваша компания устраивает важное мероприятие. Пиарщики ищут хотя бы шесть инфопартнёров, чтобы обеспечить освещение этого события. По опыту, соглашается примерно одно из пяти медиа, с которыми начинаются переговоры. Постройте распределения вероятностей и гистограммы для случайной величины «количество инфопартнёров», если вы начали переговоры с 30 медиа.
```python
from matplotlib import pyplot as plt
from math import factorial
p = 0.2 # какова вероятность заключить контракт?
n = 30  # со сколькими компаниями начинаем переговоры?

distr = [] # переменная, в которой будете хранить значения распределения

for k in range(0, n + 1):
    # постройте распределение вероятностей
    c=factorial(n) / (factorial(k) * factorial(n - k))
    P=c*p**k*(1-p)**(n-k)
    distr.append(P)
# постройте гистограмму распределения вероятностей
plt.bar(range(0, n + 1),distr)
```

#### Урок 7. Задача 3
  Постройте распределения вероятностей и гистограммы для случайной величины «количество инфопартнёров», если вы начали переговоры с 45 (60) медиа.
```python
from matplotlib import pyplot as plt
from math import factorial
p = 0.2 # какова вероятность заключить контракт?
n = 45  # со сколькими компаниями начинаем переговоры?

distr = [] # создайте переменную, в которой будете хранить значения распределения

for k in range(0, n + 1):
    # постройте распределение вероятностей
    c=factorial(n) / (factorial(k) * factorial(n - k))
    P=c*p**k*(1-p)**(n-k)
    distr.append(P)
# постройте гистограмму распределения вероятностей
plt.bar(range(0, n + 1),distr)

n = 60  # со сколькими компаниями начинаем переговоры?
for k in range(0, n + 1):
    # постройте распределение вероятностей
    c=factorial(n) / (factorial(k) * factorial(n - k))
    P=c*p**k*(1-p)**(n-k)
    distr.append(P)
# постройте гистограмму распределения вероятностей
plt.bar(range(0, n + 1),distr)
```

### [Урок 9. Нормальное распределение](https://practicum.yandex.ru/trainer/data-scientist/lesson/bec87f53-ce13-4789-8be1-1d5ddc85f447/task/0a5e34cf-6041-4734-a58b-e69fa8e3cb0e/)
Ключевая теорема в статистике — центральная предельная теорема, или ЦПТ. Её смысл в следующем: «Много независимых случайных величин, сложенных вместе, дают близкое к нормальному распределение». Такое распределение характерно для разных величин: роста людей, массы полуфабрикатов, длин деталей, ошибок измерения приборов. На каждую величину влияют факторы, которые зачастую сложно учесть, но в результате распределение этой величины стремится к нормальному.
Не только нормальное распределение описывает реальные величины. Но в силу ЦПТ оно ключевое и встречается чаще всего. Почему ЦПТ подходит для описания множества наблюдений? Известный математик Анри Пуанкаре так написал об этом в своём эссе «О науке»: «Теоретики полагают, что это эмпирический факт, а эмпирики думают, что это доказанная теорема». Не самое полное объяснение, но ничего лучше пока нет.
Нормальное распределение принципиально отличается от биномиального.
Биномиальное распределение|Нормальное распределение
-|-
Дискретно. Используется для описания дискретных случайных величин.|Непрерывно, поэтому описывает распределение непрерывных случайных величин. Дискретные случайные величины тоже могут приближённо описываться нормальным распределением, но нужно помнить, что это аппроксимация.
Бывает скошенным. Особенно если вероятность успеха близка к нулю или единице и эксперимент повторяется малое количество раз.|Всегда симметрично.
Биномиальные вероятности всегда распределены по конечному числу значений — n.|Функция плотности вероятности определена для всех значений от минус до плюс бесконечности.
Нормальное распределение определяют два параметра — среднее и дисперсия:
X∼N(μ,σ²)
Эта запись читается так: переменная X распределена нормально со средним мю (μ) и дисперсией сигма в квадрате (σ²), то есть стандартным отклонением сигма.
Попробуйте самостоятельно выставить значения μ и σ в интерактивной иллюстрации ниже. Посмотрите, как меняется график нормального распределения в зависимости от разных параметров. Проценты показывают приблизительную вероятность попасть в интервал между целыми значениями стандартных отклонений от μ — центра распределения.
На графике заметна закономерность: чем больше значение σσ, тем шире интервалы вероятностей. Большее стандартное отклонение указывает на меньшую определённость в том, какое значение может принять случайная величина. Следовательно, диапазон, в котором она может быть найдена, увеличивается.

Часто параметры распределения известны (если не точно, то по выборке — достаточно близко). Чтобы найти вероятность попадания значений в те или иные интервалы, понадобятся два метода из пакета `scipy.stats`: `norm.ppf` и `norm.cdf`.
Слово _norm_ в именах методов означает «нормальное распределение непрерывной случайной величины» (от англ. _normal continuous random variable)_. Буквы после точки расшифровываются так:
-   `ppf` — от англ. _percent point function_ — «функция процентных значений»;
-   `cdf` — от англ. _cumulative distribution function_ — «кумулятивная функция распределения».
Обе функции работают с нормальным распределением, заданным своими средним и стандартным отклонением:
-   Метод `norm.ppf` выдаёт _значение переменной_ для известной вероятности интервала слева от этого значения.
-   Метод `norm.cdf`, наоборот, выдаёт для известного значения _вероятность интервала_ слева от этого значения.
Поясним работу функций на примере: возьмём нормальное распределение со средним и стандартным отклонением, равными 1000 и 100 соответственно. Нанесём эти значения на знакомый график с вероятностью попасть в интервалы между целыми стандартными отклонениями от среднего.
![image|320x240](https://pictures.s3.yandex.net/resources/99.7____1640793268.jpg)
Нормальное распределение задаёт метод `norm()` из пакета `scipy.stats` с двумя аргументами: математическим ожиданием и стандартным отклонением.
```python
from scipy import stats as st
# задаём нормальное распределение с математическим ожиданием 1000 
# и стандартным отклонением 100
distr = st.norm(1000, 100) 

x = 1000
result = distr.cdf(x) # считаем вероятность получить значение x 
print(result)
```
`=0,5`
Вероятность того, что x≤1100:
P(X≤x) = P(X≤1100) = 84.13%
Другой пример использования метода — найти вероятность попасть между значениями 900 и 1100. Для этого достаточно вычесть кумулятивную вероятность (`cdf`) меньшего значения из кумулятивной вероятности большего значения: «хвост» распределения левее меньшего значения сократится и останется только интервал между значениями.
```python
from scipy import stats as st
distr = st.norm(1000, 100) 

x1 = 900
x2 = 1100
result = distr.cdf(x2) - distr.cdf(x1)
print(result)
```
Результат:
```
0.6826894921370859
```
В интерактивной иллюстрации вы можете выбрать другие границы интервала. Посмотрите, как будет изменяться вероятность того, что нормально распределённая случайная величина со средним 1000 и стандартным отклонением 100 окажется в заданных границах:
Вероятность того, что случайная величина примет значение между 800 и 1200
P(a≤X≤b) = P(X≤b) – P(X≤a) = P(X≤1200) – P(X≤800) = 95.45%
И, наконец, проверим функцию `ppf`, то есть найдём значение по вероятности. В `р1` зададим вероятность, примерно равную 84.13%:
```python
from scipy import stats as st
distr = st.norm(1000, 100) 
p1 = 0.841344746
result = distr.ppf(p1)
print(result)
```
Результат:
```
1099.999999971673 
```
84.13% — примерная вероятность того, что значение нормально распределённой случайной величины будет меньше, чем среднее плюс одно стандартное отклонение. Для этого распределения: 1000 + 100 = 1100, что и выдал метод `ppf`.

#### Урок 9. Задачи
1. 
Количество посетителей сайта интернет-издания «Кукуруза» за месяц распределено нормально со средним, равным 100500 человек, и стандартным отклонением в 3500 человек.
Рекламодатель, заказавший рекламу, настоял на штрафе, если материал посмотрит меньше 92000 посетителей. Его желание понятно: никто не хочет переплачивать, если охват будет не такой большой, как хотелось. В ответ менеджер сайта предложил включить в договор бонус, если материал посмотрит более 111000 человек.
Предположим, что дополнительных действий по привлечению трафика запланировано не было. Найдите вероятность того, что сайт интернет-издания за следующую неделю посетит: 
а) менее 92000 человек; б) более 111000 человек.

```python
from scipy import stats as st
mu = 100500# чему равно среднее значение распределения
sigma = 3500# чему равно стандартное отклонение распределения

bonus_threshold = 111000# где проходит граница для бонуса
penalty_threshold = 92000# где проходит граница для штрафа

p_bonus = 1-st.norm(mu,sigma).cdf(bonus_threshold) # посчитайте вероятность получить бонус
p_penalty = st.norm(mu,sigma).cdf(penalty_threshold)# посчитайте вероятность получить штраф

print('Вероятность бонуса:', p_bonus)
print('Вероятность штрафа:', p_penalty)
```

2.
Интернет-магазин «Супервип» продаёт сувенирную продукцию для узкой аудитории корпоративных клиентов. Продажи премиальных шахмат из хрусталя за неделю распределены нормально со средним значением 420 и стандартным отклонением 65.
Сколько отделу закупок нужно заказать хрустальных шахмат, чтобы продать их все на следующей неделе с вероятностью 90%? Склад перед поставкой на следующую неделю будет уже пуст.
```python
from scipy import stats as st
mu = 420 # чему равно среднее значение распределения
sigma = 65 # чему равно стандартное отклонение распределения
prob = 0.9 # с какой вероятностью нужно распродать весь товар?

n_shipment = st.norm(mu,sigma).ppf(1-prob) # сколько единиц товара нужно заказать 

print('Нужно заказать единиц товара:', int(n_shipment))
```

3.
В интернет-магазине «Вазон» пользователи делают заказы, стоимости которых распределены нормально со средним 2400 руб. и стандартным отклонением 320 руб.
Бóльшая часть покупателей выбирает доставку курьером, на которую нужно установить фиксированную цену независимо от суммы заказа.
Если верить исследованию, пользователи расстраиваются, когда стоимость доставки больше или равна половине стоимости заказа. Сколько должна стоить курьерская доставка, чтобы для ³⁄₄ заказов она не превышала половины цены?
```python
from scipy import stats as st

mu = 2400 # чему равно среднее значение распределения
sigma = 320 # чему равно стандартное отклонение распределения
threshold = 0.75 # какая доля заказов должна быть дороже двух стоимостей доставки?

max_delivery_price = st.norm(mu,sigma).ppf(1-threshold)/2 # какую стоимость доставки установить?
print('Максимальная стоимость доставки курьером:', max_delivery_price)
```

### [Урок 10. Нормальная аппроксимация биномиального распределения](https://practicum.yandex.ru/trainer/data-scientist/lesson/d5fcdad2-829e-4ea0-bbe8-a7af6ecc782c/task/dc4803ee-b4e6-47ce-b1f3-df4600217ada/)

При большом количестве повторений простого биномиального эксперимента биномиальное распределение приближается к нормальному.
Для дискретного биномиального распределения, заданного числом повторов эксперимента `n` и вероятностью успеха `p`, математическое ожидание равно `n*p`, а дисперсия: `n*p*(1-p)`.
Напомним, математическое ожидание — это значение, к которому будет стремиться средний результат эксперимента, если повторять его много раз. Биномиальный эксперимент, в свою очередь, сам по себе состоит из n повторений простого эксперимента с двумя исходами.
Поясним на примере. Когда программист Аристарх дописывает важную часть программы, он нажимает кнопку «скомпилировать и выполнить код». Аристарх — очень хороший программист: каждый пятый раз программа компилируется и выполняется без ошибок (p = 0.2p=0.2). В день он успевает написать 5050 важных частей для своих программ.
Получается, каждый день Аристарх проводит биномиальный эксперимент с мат. ожиданием 50⋅0.2 = 1050⋅0.2=10 и дисперсией 50⋅0.2⋅0.8 = 850⋅0.2⋅0.8=8, то есть со стандартным отклонением \sqrt8 = 2\sqrt28​=22​.
Конечно, за какую-то конкретную рабочую неделю среднее число выполненных с первого раза без ошибок программ может отличаться от десяти. Если Аристарх устал, с первого раза компилируется не каждая пятая, а каждая десятая-двадцатая программа. Если он на пике продуктивности — каждая третья, вторая или даже первая.
Однако, если понаблюдать за работой Аристарха подольше, среднее количество за все дни будет стремиться к десяти, а около 99%99 значений будут лежать в диапазоне 10 ± 3⋅2\sqrt210±3⋅22​, то есть примерно от 22 до 1818 скомпилированных с первого раза программ в день.
Если nn больше 5050, параметры биномиального распределения — математическое ожидание n⋅pn⋅p и дисперсию n⋅p⋅(1-p)n⋅p⋅(1−p) — можно взять как среднее и дисперсию для нормального распределения, которое будет достаточно близко описывать биномиальное.
Вот, например, биномиальное распределение для n=50n=50 и p=0.8p=0.8 и соответствующее ему нормальное распределение:
![image|320](https://pictures.s3.yandex.net/resources/Untitled_1564265649.png)
Дискретные столбцы — биномиальное распределение, а непрерывная кривая — нормальное.
Таким образом, максимально близкое к биномиальному нормальное распределение задаётся его математическим ожиданием n⋅pn⋅p в качестве среднего значения и дисперсией n⋅p⋅(1-p)n⋅p⋅(1−p).
Построим биномиальное распределение с n=50n=50 и p=0.8p=0.8. Сравним его с нормальным распределением с такими же математическим ожиданием и дисперсией, как у этого биномиального распределения, отобразив их на одном графике:

```PYTHON
from matplotlib import pyplot as plt
from math import factorial
from scipy.stats import norm
import scipy.stats

# Биномиальное распределение
p = 0.8
n = 50
binom = []
for k in range(0,n+1):
    choose = factorial(n)/(factorial(k) * factorial(n-k))
    prob = choose * p**k * (1-p)**(n-k) 
    binom.append(prob)

# Нормальное распределение
mu = n * p
var = n * p * (1-p)
sigma = var ** .5

x = range(25, n+1)
  
plt.bar(range(25, n + 1), binom[25:], alpha=0.3)
plt.plot(x, scipy.stats.norm.pdf(x, mu, sigma))
plt.show() 
```
![image|320](https://pictures.s3.yandex.net/resources/_5_1564265745.png)
В продуктовой аналитике n обычно больше 5050, и обращаться к нормальному распределению удобнее.
К примеру, на краудсорсинг-сервисе блогеры собирают донаты. Авторам лучшего контента вы дарите дополнительное продвижение: 50005000 показов рекламы их творчества на главной странице сервиса. Блогеры довольны — с показов рекламы на их страницы переходит 15\%15% пользователей. Это по 750750 переходов с 50005000 показов.
Один блогер — автор лучшего контента — получил лишь 715715 переходов вместо ожидаемых 750750. И возмутился, ведь в прошлый раз переходов было больше. Обратившись к статистике, разрешите конфликт с создателем контента. Насколько вероятно получить такое или меньшее число переходов?
Каждый пользователь видит рекламу и с вероятностью 15\%15% кликает по ней. Предполагая, что пользователи делают это независимо, получаем биномиальное распределение с n=5000n=5000 и p=0.15p=0.15. Аппроксимируем биномиальное нормальным распределением. Это значит найти такое нормальное распределение, которое максимально близко описывает это биномиальное, задав ему такие же среднее и дисперсию, как у биномиального.
Найдём вероятность получить 715715 кликов или меньше, применив метод `cdf()`:
```PYTHON
from scipy import stats as st
import math as mt

binom_n = 5000
binom_p = 0.15
bloger_clicks = 715

mu = binom_n * binom_p
sigma = mt.sqrt(binom_n * binom_p * (1 - binom_p))
p_clicks = st.norm(mu, sigma).cdf(bloger_clicks)
print(p_clicks)

0.08284191945650154 
```
Вероятность случайно получить 715715 переходов вместо 750750 — небольшая, примерно 8.3\%8.3%. Однако не настолько маленькая, чтобы это событие практически не случалось.
С учётом этой вероятности можно утверждать, что из каждых 100100 блогеров, чей контент заслужил дополнительного продвижения, восемь будут получать 715715 кликов или меньше. Получается, это совсем не редкое событие, и претензии блогера неуместны.

#### Урок 10. Задачи
Компания делает ежемесячную рассылку по базе клиентов — в ней новости и предложения от партнёров. Известно, что рассылку открывают 40% получателей.
Один партнёр спланировал рекламную кампанию и рассчитывает на охват в 9 тысяч пользователей. Посчитайте, с какой вероятностью ожидания клиента будут оправданы, если сделать рассылку на 23 тысячи человек. Выведите значение _p_threshold_ на экран.
```python
from scipy import stats as st
import math as mt

binom_n = 23000 # ваш код здесь - целевое количество человек в рассылке
binom_p = 0.4 # ваш код здесь - сколько пользователей открывают рассылку?

threshold = 9000 # ваш код здесь - на какой охват сейчас рассчитывают?

mu =  binom_n*binom_p # чему равно среднее значение распределения
sigma = mt.sqrt(binom_n*binom_p*(1-binom_p))# чему равно стандартное отклонение распределения

p_threshold = 1-st.norm(mu,sigma).cdf(threshold)# ваш код здесь
print(p_threshold)
```


Чтобы ничего не забыть, скачайте [шпаргалку](https://code.s3.yandex.net/data-analyst/conspects/praktikum_data_analysis_takeaways_course4_theme2.pdf) и [конспект](https://code.s3.yandex.net/data-analyst/conspects/praktikum_data_analysis_abstract_course4_theme2.pdf) темы.

[Основные понятия теории вероятностей](https://web.archive.org/web/20201130231139/http://mathhelpplanet.com/static.php?p=osnovnye-ponyatiya-tyeorii-veroyatnostyei).


### [Урок 12. Проверочные задания. Теория вероятностей](https://practicum.yandex.ru/trainer/data-scientist/lesson/cc1f4c73-b8e0-4eb3-a5a3-c2dca533ff23/task/11df3d1b-9413-4845-bab1-3d58d03d0286/)


