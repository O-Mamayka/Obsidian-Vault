## [DS.04. Статистический анализ данных. Тема 03. Теория вероятностей](https://practicum.yandex.ru/trainer/data-scientist/lesson/ebe1ad5b-998e-4cff-910d-225a8f2952c1/task/03ff3dd3-bc30-438d-b12f-6aa34d9f91de/)

Вы изучите основы аксиоматики Колмогорова: узнаете, чем событие отличается от случайной величины и как устроены некоторые важные — часто наблюдаемые в реальном мире — распределения вероятностей.

-   понимать закон больших чисел и центральную предельную теорему (в одной из формулировок);
-   моделировать биномиальное распределение на Python, аппроксимировать его нормальным распределением в тех случаях, когда это возможно;
-   работать с нормальным распределением на Python: искать значения по вероятностям и наоборот.


### [Урок 2. Эксперименты, элементарные исходы, события](https://practicum.yandex.ru/trainer/data-scientist/lesson/33a9da3e-6ac1-4573-8e3a-cd7f536a181a/)

**Эксперимент** — это повторяемый опыт, который может окончиться **элементарными исходами**. Они так названы из-за своего простого устройства: исход либо случился, либо нет.
В простейшем случае исходы не отличаются: вероятность каждого из них одинакова. Такие исходы называются **равновероятные**.
-   Пустое множество. Оно не содержит ничего: с точки зрения математики, это законно. Вы уже знаете, что если эксперимент проведён, какой-то элементарный исход должен стать его результатом. Вероятность пустого подмножества при этом равна нулю — поэтому событие, состоящее из пустого подмножества вероятностного пространства, называется **невозможным;**
-   Множество, содержащее в себе все возможные исходы — подмножество вероятностного пространства, равное ему самому. Такое событие точно, с вероятностью 1, произойдет при проведении эксперимента, поэтому оно называется **достоверным**.
Остальные события расположены между этими крайностями, и их вероятность лежит в промежутке от 0 до 1.
При сохранении условия равновероятности всех элементарных исходов **вероятность события** — количество исходов, входящих в это событие, делённое на общее количество исходов, то есть на размер вероятностного пространства.
Исходы — это песни, которые могут быть проигранными первыми, а событие — то, что первая включённая песня принадлежит группе _Queen_. Так, событие состоит из нескольких исходов.
Не дайте себя обмануть! Выражение «исход события» не имеет смысла. Исходы бывают только у эксперимента, и могут попасть в подмножество, названное событием, или не попасть.

### [Урок 3. Закон больших чисел](https://practicum.yandex.ru/trainer/data-scientist/lesson/7017a06d-bce6-4a2b-b5e8-712d37632d0d/task/3a588b32-fcc9-4bb9-816c-8fc271c833bc/)
Вероятность события тесно связана с его частотой при многократном повторении эксперимента.

**Закон больших чисел** — известная закономерность: чем больше раз повторяется эксперимент, тем ближе частота заданного на этом эксперименте события будет к его вероятности. Если многопятновый питон — обладатель 7 или 8 пятен, а всего пятен может быть от 3 до 8, то чем больше питонов вырастет в питоноинкубаторе, тем ближе к 1/3 будет доля многопятновых среди них.
Это правило работает и в обратную сторону. Если мы не знаем вероятность какого-нибудь события, но можем много раз повторить эксперимент, то о ней можно судить по частоте входящих в него исходов.

#### Урок 3. Задача
Яндекс отслеживает количество удачных постов определённого блога для Дзена. Абсолютно удачным постом считается такой, у которого число репостов сравнимо с числом лайков. Этот успех считаем за 100%.
Сгенерируйте 20, 400, 10000 случайных целых чисел из отрезка [1, 100]. Это соотношение репостов к лайкам в популяции блогеров в целом. Если для избранного блогера соотношение всегда выше, он причисляется к хорошим.
Для каждого набора чисел вычислите вероятность события «Сгенерированное число лежит в отрезке [21, 40]» (самая типичная доля репостов). Сохраните её в переменных `p_20`, `p_400` и `p_10000` соответственно.
```python
import random
random.seed(1111)  # метод seed() задаёт степень случайности, не меняйте её
def calculate_p(N):
    cnt_21_40 = 0
    for i in range(N):
        random_integer = random.randint(1,100) # ваш код здесь
        if (random_integer >=21) and (random_integer<=40):
            cnt_21_40 +=1
    return cnt_21_40/N

p_20 = calculate_p(20)
p_400 = calculate_p(400)
p_10000 = calculate_p(10000)
print(p_20, p_400, p_10000)
out: 0.15 0.255 0.2003
```
По закону больших чисел: чем больше раз повторяется эксперимент, тем ближе частота события к его вероятности. В этой задаче — к 20%. Если у вас при увеличении числа экспериментов вероятность события становится дальше от 20%, не пугайтесь. Вероятность этого очень мала, но не нулевая.

### Урок 4. Взаимоисключающие и независимые события, умножение вероятностей
Для каждого из шести исходов взросления первого питона может выпасть шесть исходов взросления второго — всего 36. Их можно обозначить так:

![image|320x240](https://pictures.s3.yandex.net/resources/5-3-3-1_1565075900.jpg)
Разными цветами обозначены события «суммарно на двух питонах появилось _k_ пятен» (_k_ может быть от 2 до 12). Вероятности этих событий не равны: в них входит разное количество элементарных исходов.
Некоторые события могут иметь общие исходы — на диаграмме, отображающей все элементарные исходы, они пересекутся.
Например, будут иметь общие исходы событие А — на питонах в сумме появилось больше восьми пятен — и событие Б — на питонах появилось одинаковое количество пятен:
![image|320x240](https://pictures.s3.yandex.net/resources/____4_1564228721.jpg)
Элементарные исходы «на обоих питонах появилось по пять пятен» (в сумме десять) и «на обоих питонах появилось по шесть пятен» (в сумме двенадцать) входят в оба события.
Схематично такой случай можно отобразить на **диаграмме Эйлера-Венна**. На ней не указывают элементарные исходы, а лишь отношения пересечения между событиями:

![image|200x120](https://pictures.s3.yandex.net/resources/jpg_1_1564227904)
События А и Б пересекаются, значит существуют элементарные исходы, входящие и в А, и в Б.
**Взаимоисключающими** называют события, которые не могут произойти одновременно при проведении эксперимента — на диаграмме Эйлера-Венна они не пересекаются. Вероятность пересечения взаимоисключающих событий равна нулю.
События называют **независимыми**, если наступление одного из них не влияет на вероятность другого.
**Когда события независимы, то вероятность их пересечения равна произведению их вероятностей.** Это правило работает и в обратную сторону.
На том же вероятностном пространстве события «у одного из питонов ровно два пятна» и «у питонов в сумме 7 пятен», **Зависимы**. Вероятность семи пятен в сумме равна 6/36 или 1/6; вероятность ровно двух пятен у одного из них — 11/36; вероятность пересечения — 2/36. 1/6 * 11/36 ≠ 2/36: события зависимы. Наступление одного из них меняет вероятность наступления другого.

![image|240](https://pictures.s3.yandex.net/resources/pitony2_1656501621.jpg)
Взаимоисключающие события **не** могут быть независимыми, вероятность каждого из которых больше нуля! Чтобы события были независимыми, вероятность их пересечения должна быть равна произведению их вероятностей. Произведение их вероятностей будет точно больше нуля, ведь по условию задачи у каждого из них ненулевая вероятность. А вероятность пересечения взаимоисключающих событий равна нулю. Условие независимости не может быть выполнено. Это логично: наступление одного из этих событий исключает наступление другого, то есть влияет на вероятность, что оно произойдет. А значит, взаимоисключающие события не независимы.
Если взаимоисключающие события охватывают всё вероятностное пространство, сумма их вероятностей равна единице.
Взаимоисключаемость событий видна на диаграмме **Эйлера-Венна**. А вот независимость так просто не обнаружишь, нужно проверять условие равенства произведения вероятностей событий вероятности их пересечения. Для нахождения вероятности пересечения независимых событий (произойдёт и то, и другое) нужно найти произведение их вероятностей.
Пускай питон ползёт по лабиринту в попытках найти выход. На каждом разветвлении он с равной вероятностью выбирает один из доступных ему путей.
![image|320](https://pictures.s3.yandex.net/resources/Labirint_1589282118.png)
На первой развилке у него два варианта продолжения пути; на второй — три; на третьей — пять. Только на одном из тридцати возможных путей питон достигнет свободы. Вероятности можно перемножать, так как выбор происходит независимо от предыдущих.
_Вероятность того, что случайный пользователь указал мужской пол, равна 0,29. Вероятность, что случайный пользователь не указал свой пол, равна (1 - 0,29 - 0,25) = 0,46. События независимы. Значит, вероятность того, что они произойдут именно в таком порядке, равна 0,46 * 0,29 = 0,1334 или 13,34 %._

### Урок 5. Случайные величины, распределение вероятностей и интервалы значений
эксперимент, элементарные исходы, события и вероятность - это набор поможет понять смысл **случайной величины**.
Случайная величина — это переменная, которая принимает случайные значения. «Случайные» — значит нельзя предсказать, какое именно значение примет величина. У эксперимента есть исходы, которые могут описываться как количественно, так и качественно.
Случайная же величина определяется на этих исходах _численно_. Это способ спроецировать исходы эксперимента, как бы они ни определялись, на числовую ось.

Для одного и того же эксперимента это делают по-разному. Например, исход эксперимента, когда питон выбирается из лабиринта, можно обозначить нулём. А когда не выбрался — единицей. Или наоборот. Или же сотней, если выбрался, и тысячей — если нет. После такого определения можно работать с числами, обычно это удобнее.
Как и все количественные переменные, случайная величина может быть дискретной или непрерывной. Например, масса питонов — непрерывная величина, а количество питонов, достигших возраста покрывания пятнами — дискретная.
Соберём все возможные значения сумм и укажем соответствующие им вероятности в таблице:

Случайная величина «Сумма пятен на двух питонах»

Вероятность этого значения

Случайная величина «Сумма пятен на двух питонах»|Вероятность этого значения 
 -|-
 2|1/36
 3|2/36
 4|3/36
 5|4/36
 6|5/36
 7|6/36
 8|5/36
 9|4/36
 10|3/36
 11|2/26
12|1/36|
Такая таблица называется **распределением вероятностей** случайной величины.
Построим такую таблицу в Python. Поместим данные о пятнах питона в массив _numpy array_:
```python
spots = np.array([[2,3,4,5,6,7], # имя переменной spots по-английски значит «пятна»
    [3,4,5,6,7,8], 
    [4,5,6,7,8,9], 
    [5,6,7,8,9,10], 
    [6,7,8,9,10,11],
    [7,8,9,10,11,12]])
```

```
spot_probs={k:spot_counts[k]/36 for k in spot_counts}
print(spot_probs)
```
Выражение, которое мы применили — генератор данных для словаря. В документации или англоязычной литературе вы можете встретить его другое название: _dictionary comprehension_ (англ. «описание словаря»).
Если мы возьмём не сумму, а произведение количества пятен, это будет другая случайная величина. Вероятностное пространство будет выглядеть так:
![image|220](https://pictures.s3.yandex.net/resources/____1.1_1564231614.jpg)
Найдем распределение вероятностей для этого вероятностного пространства и построим гистограмму:
```python
import pandas as pd
x = pd.Series([1, 2, 3, 4, 5, 6, 2, 4, 6, 8, 10, 12, 3, 6, 9, 12, 15, 18, 4, 8, 12, 16, 20, 24, 5, 10, 15, 20, 25, 30, 6, 12, 18, 24, 30, 36])
x.hist(density=True, bins=36)
```
Аргумент _density_ со значением _True_ нужен для построения гистограммы плотности вероятностей. Количество корзин равно количеству значений — это значит, что по вертикальной оси будут вероятности для каждого значения.
Получим гистограмму:
![image|240](https://pictures.s3.yandex.net/resources/Untitled_1564231681.png)
Наиболее вероятные значения: 6 и 12. Они встречаются в вероятностном пространстве по 4 раза, то есть вероятность каждого из них — 4/36 или 1/9.
Заметим, что для любой случайной величины выполняется известное вам правило: сумма вероятностей всех возможных исходов равна единице.


#### Урок 5. Задача 1
`spot_matrix` - «сумма количества пятен двух питонов, у которых с равной вероятностью могут появиться от 5 до 10 пятен».
Составьте словарь `spot_probs` с распределением вероятностей для этой случайной величины. Ключами в словаре должны быть целые числа — возможные исходы эксперимента (тип `int`), значениями — вероятности исходов типа `float`. Выведите значение переменной `spot_probs` на экран.
Попробуйте проитерироваться по возможным значениям количества пятен для первого питона, и для каждого из них проитерироваться по количеству пятен для второго питона. Сумма, полученная на каждой итерации — это исход эксперимента.
```python
import numpy as np
spot_matrix = np.array(
    [
        [10, 11, 12, 13, 14, 15],
        [11, 12, 13, 14, 15, 16],
        [12, 13, 14, 15, 16, 17],
        [13, 14, 15, 16, 17, 18],
        [14, 15, 16, 17, 18, 19],
        [15, 16, 17, 18, 19, 20],
    ]
)
spot_counts = {}
for i in range (0,6):
    for j in range (0,6):
        if spot_matrix[i][j] not in spot_counts.keys():
            spot_counts[spot_matrix[i][j]] = 1
        else:
            spot_counts[spot_matrix[i][j]] += 1

spot_probs = {k:spot_counts[k]/36 for k in spot_counts } # код словаря
print(spot_probs)
```

#### Урок 5. Задача 2
Проверьте, что сумма вероятностей всех возможных исходов равна единице. Округлите результат и запишите в переменную `sum_probs_one`. Выведите её на экран. Не удаляйте вывод `spot_probs` из предыдущего задания.
Значения словаря получают вызовом метода `values()`, а их сумму — передавая значения как аргумент методу `sum()`. Чтобы обойтись без квадриллионных долей, округлите результат.
```python
sum_probs_one = int(sum(spot_probs.values()))
```

### Урок 6. Математическое ожидание и дисперсия
чем больше раз повторяется эксперимент, тем ближе частота заданного на эксперименте события будет к его вероятности.
Если событие — подмножество вероятностного пространства, значит, можно взять все возможные исходы и объявить их событием. Применим закон больших чисел: к чему будут стремиться результаты эксперимента, если повторять его много раз? Для эксперимента можно задать случайную величину и найти численное значение, к которому она будет в среднем стремиться при многократном повторе эксперимента. Это значение называется математическим ожиданием случайной величины.
Если эксперимент состоит из равновероятных элементарных исходов, заданных численно, математическое ожидание будет равно среднему возможных значений.
Если выращивать сотни питонов вида от-одного-до-шести-пятновые, то даже если у первых нескольких питонов будет очень мало или очень много пятен, с ростом количества наблюдений среднее количество пятен будет стремиться к `(1+2+3+4+5+6)/6 = 3,5`.
Стремление значений к математическому ожиданию иллюстрирует график:
![image|320](https://pictures.s3.yandex.net/resources/jpg_1564562604)
Математическое ожидание равно среднему, если исходы равновероятны. Но что если вероятности разных значений случайной величины отличаются? К чему тогда будет стремиться среднее при повторении экспериментов?
**Математическое ожидание случайной величины** — сумма всех значений случайной величины, помноженных на их вероятности:
![image|340](https://pictures.s3.yandex.net/resources/Screenshot_1564261717.png)
Математическое ожидание случайной величины _X_ обозначается буквой _E_ (от англ. _expected value,_ «ожидаемое значение»); вероятность значения _x_ — буквой _p_ (от лат. _probabilitas_, «вероятность»).
К примеру, пусть распределение вероятностей случайной величины задано таблицей:
![image](https://pictures.s3.yandex.net/resources/jpg_1_1564261766)
Преобразуем таблицу в словарь и найдём математическое ожидание по формуле:
```python
x_probs = {
        '3': 0.1,
        '4': 0.2,
        '5' : 0.2,
        '7' : 0.3,
        '11' : 0.1,
        '16' : 0.05,
        '18': 0.05    
}
# E(X): для каждого элемента словаря вычисляем произведение вероятности и значения 
# случайной величины (целочисленное представление ключа словаря):
expectation = sum([int(x_i)*x_probs[x_i] for x_i in x_probs]) 
print(expectation)
```




Математическое ожидание — аналог характеристики положения, только не для датасета, а для случайной величины. Оно показывает, вокруг какого значения распределена случайная величина, и — по закону больших чисел — к какому значению она будет в среднем стремиться при повторениях эксперимента.
Поскольку случайная величина распределена вокруг этой «характеристики положения», можно найти и меру её разброса.
Для этого нужно найти математическое ожидание квадрата случайной величины. Это несложно, ведь значения меняются, а их вероятности — нет.
Зная математическое ожидание самой случайной величины и её квадрата, дисперсию находят по формуле:
![image|480](https://pictures.s3.yandex.net/resources/Screenshot_1_1564261849.png)
Распределение вероятностей случайной величины задано таблицей:
![image|480](https://pictures.s3.yandex.net/resources/jpg_1564261922)

```python
x_probs = {
    '3': 0.1,
    '4': 0.2,
    '5': 0.2,
    '7': 0.3,
    '11': 0.1,
    '16': 0.05,
    '18': 0.05
}
# E(X): для каждого элемента словаря вычисляем произведение вероятности и значения
# случайной величины (целочисленное представление ключа словаря):
expectation = sum([int(x_i) * x_probs[x_i] for x_i in x_probs])
# (E(X))^2
square_of_expectation = expectation ** 2
# E(X^2)
expectation_of_squares = sum(
    [int(x_i) * int(x_i) * x_probs[x_i] for x_i in x_probs]
)
variance = expectation_of_squares - square_of_expectation
print(variance) 
```

```
Out: 15.899999999999991 
```

Корень из дисперсии примерно равен четырём — это стандартное отклонение. Математическое ожидание равно семи.
Правило трёх сигм работает: в промежутке 7 ± (4 * 2) расположены все значения, кроме 16 и 18, а в промежутке 7 ± (4 * 3) лежат все значения случайной величины.

#### Урок 6. Задача 1
В переменной `x_probs` в виде словаря задано распределение вероятностей случайной величины _X —_ апрельской температуры в городе _N_. Найдите её математическое ожидание и дисперсию. Сохраните результаты в переменных `expectation`(англ. «ожидание») и `variance` (англ. «разброс»). Выведите их на экран.
Найдите математическое ожидание и дисперсию по формулам из урока.
Найти математическое ожидание можно так:
```python
expectation = sum([int(x_i)*x_probs[x_i] for x_i in x_probs]) 
```
Для нахождения дисперсии посчитайте квадрат математического ожидания и математическое ожидание квадратов:
```python
square_of_expectation = expectation ** 2
expectation_of_squares = sum([int(x_i)*int(x_i)*x_probs[x_i] for x_i in x_probs]) 
```
Для нахождения дисперсии найдите разность между математическим ожиданием квадратов и квадратом математического ожидания.
```python
import numpy as np
x_probs = {
    '-4': 0.05,
    '-2': 0.25,
    '0': 0.1,
    '1': 0.1,
    '5': 0.1,
    '7': 0.05,
    '15': 0.35,
}

# здесь код ваших вычислений
expectation=sum(int(key)*x_probs[key] for key in x_probs)
expectation_x2=sum(int(key)**2*x_probs[key] for key in x_probs)
variance=expectation_x2-expectation**2
print('Математическое ожидание равно', expectation)
print('Дисперсия равна', variance)
```

```
Математическое ожидание равно 5.5
Дисперсия равна 55.349999999999994
```

#### Урок 6. Задача 2
Известно, что питоны разных знаков Зодиака дорастают до различного взрослого веса. Водные знаки весят 2 кг, Огненные и Земляные — 3 кг, Воздушные — 5 кг. Питоны рождаются с одинаковой частотой на протяжении всего года.
Запишите в словарь `weight_probs` распределение вероятностей для случайной величины «Вес питона». В качестве ключей словаря используйте строковые значения, а не числовые. Найдите математическое ожидание и дисперсию случайной величины, запишите их в переменные `expectation` и `variance`. Результат выведите на экран.
```python
import numpy as np

# Вероятность того, что отдельно взятый питон окажется одним из 12 знаков Зодиака, равна 1/12.
# Вероятность того, что он принадлежит к одной из 4 стихий, равна 1/4.
# Вероятности для двух стихий - Огня и Земли - нужно сложить, чтобы получить вероятность
# того, что питон весит 3 кг, для остальных просто остается 1/4.
weight_probs = {'2':0.25,'3':0.5,'5':0.25}
# здесь код создания словаря и расчётов
expectation=sum([int(k)*weight_probs[k] for k in weight_probs])
expectation_x2=sum([int(k)**2*weight_probs[k] for k in weight_probs])
variance=expectation_x2-(expectation)**2
print('Математическое ожидание равно', expectation)
print('Дисперсия равна', variance)
```

```
Математическое ожидание равно 3.25
Дисперсия равна 1.1875
```

### Урок 7. Вероятность успеха в биномиальном эксперименте
Часто встречаются эксперименты всего с двумя исходами. Такие эксперименты называются **биномиальными** (от лат. _bis_ — «два», _nomen_ — «имя»).
Обычно один из результатов называют успехом, а второй, соответственно, неудачей. Если вероятность успеха равна `p`, то вероятность неудачи `(1 - p)`, ведь сумма вероятностей всех исходов эксперимента должна быть равна единице.
Например, если нас интересует комбинация из четырёх подряд экспериментов: Успех-Успех-Неудача-Успех, то её вероятность можно найти по формуле `p⋅p⋅(1-p)⋅p`, если обозначить вероятность успеха за _p_.
Пользователь попадает в рекламный баннер с первого клика в 88% случаев. В 12% случаев промахивается: попадает на страницу рядом с баннером.
Какова вероятность, что из 5 независимо кликающих по баннеру пользователей первые три попадут по баннеру, а следующие двое промажут?
```PYTHON
a = 0.88 # вероятность, что пользователь попадёт по баннеру
b = 0.12 # вероятность, что пользователь промажет
prob = a * a * a * b * b
out: 0.0098131968 
```
Вероятность того, что в пятёрке независимо кликающих на баннеры пользователей случится именно такой порядок: три клика, а затем два непопадания, чуть меньше 1%.



